# >> 三百六十五萬case 經驗紀錄 << #


## 先創造表格 讀進365w結構 ##

先直接用table data import wizard匯入整個csv 再去讀取創表格的格式有時候比較快

```
SHOW CREATE TABLE yoyo.temp_import_365
```
### 創表格 ###
設定 PRIMARY KEY 為Canonical_Smiles
 和 UNIQUE KEY 為id 讓他自動編號
複製修改一下 如下
```
CREATE TABLE `3.65M__case_smiles_originaldata` (
 id INT UNSIGNED NOT NULL AUTO_INCREMENT,
 `Original_Smiles` text,
 `Canonical_Smiles` varchar(120) NOT NULL,

 PRIMARY KEY (Canonical_Smiles),
 UNIQUE KEY (id)
 )
 ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
```
接著匯入 請參考下面"改善匯入效率"





## 改善匯入效率 ##

文件my.ini中的此行設定:
設成0效率最好，但安全方面比較差，即使MySQL掛了也可能會損失當下讀寫的數據。
而值2只會在整個操作系統 掛了時才可能丟失數據。
```
innodb_flush_log_at_trx_commit=2   #實測速度提升2倍
```


以及更改
```
innodb_log_file_size=512MB
innodb_log_buffer_size=16MB
```
### 後來改用load data 指令

先創出表格
```
CREATE TABLE `3.65M__case_smiles_originaldata` (
 id INT UNSIGNED NOT NULL AUTO_INCREMENT,
 `Original_Smiles` text,
 `Canonical_Smiles` varchar(120) NOT NULL,

 PRIMARY KEY (Canonical_Smiles),
 UNIQUE KEY (id)
 )
 ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
```
再用指令匯入
```
LOAD DATA INFILE 'C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/365w_case/3649051_canonical_smile.csv'
INTO TABLE `3.65M__case_smiles_originaldata`
      FIELDS  TERMINATED BY ',' 
            #  ENCLOSED BY '"' 
      LINES   TERMINATED BY "\r"
(Original_Smiles, Canonical_Smiles)
```
然後出現 Lost connection to MySQL server during query错误
此時重新打開 登入 都會寫登入錯誤
```
slove: 想辦法殺掉mydql.exe  (我是先到電腦管理的服務關閉 結果卡在一直顯示 "正在關閉"   後來直接到工作管理員關就好了... )
```
後來改了
```
max_allowed_packet = 500M # 沒屁用
在my.ini文件中[mysqld]下增加一行net_write_timeout=600 
```

最後發現似乎是 workbench本身設定的問題 真是太瘋狂了
```
Edit > Preferences > SQL Editor--> DBMS connection read timeout interval(in second) 調大吧~~ 

總共花費8.5小時!
```


檢查表格重複數量是否合理
```
select count(*), count(DISTINCT Canonical_Smiles)
FROM `3.65m__case_smiles_originaldata`
```


## 隨機取出2w個 ##

資料庫建表
```
CREATE TABLE `3.65M__case_smiles_random_2w`
SELECT * 
FROM `3.65M__case_smiles_originaldata`
ORDER BY RAND()
LIMIT 20000
```



## 取出 前 1w個 當train data ##

資料庫建表
```
CREATE TABLE `3.65M__case_smiles_train_data_1w_from_random_2w`
SELECT * 
FROM `3.65M__case_smiles_random_2w`
LIMIT 10000    #前1w筆資料
```
若出現錯誤代碼`Error Code: 1206. The total number of locks exceeds the lock table size` 
代表預設值不讓你製作那麼大的表格
```
更改 my.ini檔案
innodb_buffer_pool_size=64M  
重啟服務
```


只取`Canonical_Smiles`欄位匯出csv 給PP計算
```
SELECT Canonical_Smiles 
INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/365w_case/3.65M__case_smiles_train_data_1w_from_random_2w_only_canonical.csv'
FROM yoyo.`3.65m__case_smiles_train_data_1w_from_random_2w`
```

使用mac terminal 切割檔案 每2000筆資料為一組 ()
```
split -l 2000 3.65M__case_smiles_train_data_1w_from_random_2w_only_canonical.csv train_data_
```

## 取出 最後 1w個 當test data ##

資料庫建表
```
CREATE TABLE `3.65M__case_smiles_test_data_1w_from_random_2w`
SELECT * 
FROM `3.65M__case_smiles_random_2w`
LIMIT 10000, 10000   #跳過前1w筆  取接著的1w筆
```

只取`Canonical_Smiles`欄位匯出csv 給PP計算
```
SELECT Canonical_Smiles 
INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/365w_case/3.65M__case_smiles_test_data_1w_from_random_2w_only_canonical.csv'
FROM yoyo.`3.65m__case_smiles_test_data_1w_from_random_2w`
```

使用mac terminal 切割檔案 每2000筆資料為一組 ()
```
split -l 2000 3.65M__case_smiles_test_data_1w_from_random_2w_only_canonical.csv test_data_
```

## xxxxx ##

yyyyyyy
```
.......
```

